{"meta":{"title":"ShaneD711's Blog","subtitle":"","description":"","author":"ShaneD711","url":"https://shaned711.github.io","root":"/"},"pages":[],"posts":[{"title":"Redis 实战：从零手写分布式锁（误删问题与 Lua 脚本优化）","slug":"Redis-实战：从零手写分布式锁（误删问题与-Lua-脚本优化）","date":"2025-12-19T07:50:22.000Z","updated":"2025-12-19T07:56:23.965Z","comments":true,"path":"2025/12/19/Redis-实战：从零手写分布式锁（误删问题与-Lua-脚本优化）/","permalink":"https://shaned711.github.io/2025/12/19/Redis-%E5%AE%9E%E6%88%98%EF%BC%9A%E4%BB%8E%E9%9B%B6%E6%89%8B%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%EF%BC%88%E8%AF%AF%E5%88%A0%E9%97%AE%E9%A2%98%E4%B8%8E-Lua-%E8%84%9A%E6%9C%AC%E4%BC%98%E5%8C%96%EF%BC%89/","excerpt":"","text":"Redis 实战：从零手写分布式锁（误删问题与 Lua 脚本优化）在单体架构中，我们习惯使用 synchronized 或 Lock 来解决并发安全问题。但在分布式集群架构下，不同的服务运行在不同的 JVM 中，本地锁也就失效了。 本文将复现如何基于 Redis 实现一个分布式锁，并一步步解决死锁、误删、原子性等经典问题。 一、 初级版本：利用 SETNX 实现互斥Redis 的 SETNX (Set if Not Exists) 命令天生具备互斥性：只有 Key 不存在时才能设置成功。 为了防止获取锁的服务器宕机导致锁永远无法释放（死锁），我们需要在使用 SETNX 的同时设置过期时间（TTL）。 核心命令： 1SET lock:key threadId NX EX 10 注意：必须保证 SETNX 和 EXPIRE 是原子操作，不能分成两条命令执行。 Java 代码实现定义一个 SimpleRedisLock 类，实现基础的加锁和解锁逻辑。 1234567891011121314151617181920212223242526272829public class SimpleRedisLock implements ILock &#123; private String name; // 锁的业务名称 private StringRedisTemplate stringRedisTemplate; // Redis操作工具 public SimpleRedisLock(String name, StringRedisTemplate stringRedisTemplate) &#123; this.name = name; this.stringRedisTemplate = stringRedisTemplate; &#125; private static final String KEY_PREFIX = &quot;lock:&quot;; @Override public boolean tryLock(long timeoutSec) &#123; // 获取线程ID作为标识 long threadId = Thread.currentThread().getId(); // 执行 SET lock:name threadId NX EX timeout Boolean success = stringRedisTemplate.opsForValue() .setIfAbsent(KEY_PREFIX + name, threadId + &quot;&quot;, timeoutSec, TimeUnit.SECONDS); // 防止自动拆箱空指针 return Boolean.TRUE.equals(success); &#125; @Override public void unlock() &#123; // 简单粗暴直接删 stringRedisTemplate.delete(KEY_PREFIX + name); &#125;&#125; 二、 进阶版本：解决“误删”问题初级版本存在一个严重的隐患：如果业务执行时间超过了锁的过期时间，会发生什么？ 1. 事故场景还原假设锁的有效期是 10s，但业务执行了 15s： 线程 A 获取锁，开始执行业务。 10s 后，Redis 锁自动过期释放。 线程 B 尝试获取锁，成功拿到（因为 A 的锁没了）。 15s 后，线程 A 业务执行完毕，执行 unlock()，直接删除了 Key。 问题出现：线程 A 删掉的其实是 线程 B 正在持有的锁！ 此时 线程 C 进来，发现没锁，直接加锁。导致 B 和 C 并发执行，互斥失效。 2. 解决方案：给锁加上“身份证”为了遵循“解铃还须系铃人”的原则，我们需要在解锁时判断：这把锁是不是我的？ 改进 Value：单用线程 ID 在集群下可能重复，我们需要拼接一个 JVM 的唯一标识（UUID）。 改进 unlock：删除前先查询 Value，判断是否与自己一致。 3. 代码升级12345678910111213141516171819202122232425262728293031import cn.hutool.core.lang.UUID;public class SimpleRedisLock implements ILock &#123; // ... 构造方法同上 ... // 生成 JVM 唯一的 UUID 前缀 private static final String ID_PREFIX = UUID.randomUUID().toString(true) + &quot;-&quot;; @Override public boolean tryLock(long timeoutSec) &#123; // 拼接 UUID + 线程 ID String threadId = ID_PREFIX + Thread.currentThread().getId(); // 存入 Redis Boolean success = stringRedisTemplate.opsForValue() .setIfAbsent(KEY_PREFIX + name, threadId, timeoutSec, TimeUnit.SECONDS); return Boolean.TRUE.equals(success); &#125; @Override public void unlock() &#123; // 1. 获取当前线程的标识 String threadId = ID_PREFIX + Thread.currentThread().getId(); // 2. 获取 Redis 中锁的标识 String id = stringRedisTemplate.opsForValue().get(KEY_PREFIX + name); // 3. 判断是否一致 if (threadId.equals(id)) &#123; // 4. 一致才删除 stringRedisTemplate.delete(KEY_PREFIX + name); &#125; &#125;&#125; 三、 终极版本：Lua 脚本保证原子性上面的 Java 代码解决了“误删”的大部分场景，但在极端并发下依然有漏洞。 1. 原子性漏洞在 unlock 方法中，“判断锁标识” 和 “删除锁” 是两个动作。 如果线程 A 判断成功（是自己的锁），正准备删除时，系统发生了 GC 停顿（Stop The World）或者网络阻塞。 恰好在这段时间内，锁过期了，线程 B 抢到了锁。 等线程 A 恢复运行，它不会再次判断，而是直接执行 delete，结果还是把 B 的锁给删了。 2. 解决方案：Lua 脚本Redis 提供了 Lua 脚本功能，可以将多条命令作为一个整体执行，中间不会被其他命令插入，从而保证了原子性。 编写 Lua 脚本 (unlock.lua)： 123456789-- KEYS[1] 是锁的 key-- ARGV[1] 是当前线程的标识if redis.call(&#x27;get&#x27;, KEYS[1]) == ARGV[1] then -- 标识一致，执行删除 return redis.call(&#x27;del&#x27;, KEYS[1])else -- 不一致，返回 0 return 0end 3. 代码最终形态我们需要预加载 Lua 脚本，并使用 execute 方法调用。 12345678910111213141516171819202122232425262728293031323334353637public class SimpleRedisLock implements ILock &#123; private String name; private StringRedisTemplate stringRedisTemplate; // 静态代码块预加载 Lua 脚本 private static final DefaultRedisScript&lt;Long&gt; UNLOCK_SCRIPT; static &#123; UNLOCK_SCRIPT = new DefaultRedisScript&lt;&gt;(); UNLOCK_SCRIPT.setLocation(new ClassPathResource(&quot;unlock.lua&quot;)); // 脚本文件位置 UNLOCK_SCRIPT.setResultType(Long.class); &#125; public SimpleRedisLock(String name, StringRedisTemplate stringRedisTemplate) &#123; this.name = name; this.stringRedisTemplate = stringRedisTemplate; &#125; private static final String ID_PREFIX = UUID.randomUUID().toString(true) + &quot;-&quot;; @Override public boolean tryLock(long timeoutSec) &#123; String threadId = ID_PREFIX + Thread.currentThread().getId(); Boolean success = stringRedisTemplate.opsForValue() .setIfAbsent(KEY_PREFIX + name, threadId, timeoutSec, TimeUnit.SECONDS); return Boolean.TRUE.equals(success); &#125; @Override public void unlock() &#123; // 调用 Lua 脚本 stringRedisTemplate.execute( UNLOCK_SCRIPT, Collections.singletonList(KEY_PREFIX + name), // KEYS[1] ID_PREFIX + Thread.currentThread().getId() // ARGV[1] ); &#125;&#125; 四、 总结手写 Redis 分布式锁是一个非常好的学习过程，经历了三个阶段： 基础版：利用 SETNX 实现互斥，EX 防止死锁。 改进版：利用 UUID + ThreadID 防止锁超时后误删他人锁。 终极版：利用 Lua 脚本 解决“查询”与“删除”非原子性的问题。 注意：这只是一个入门级的分布式锁实现。在生产环境中，还要考虑锁续期（看门狗机制）、可重入性、主从一致性（Redlock）等问题。建议生产环境直接使用成熟的框架 Redisson。","categories":[],"tags":[]},{"title":"Redis实战: “一人一单”功能的实现逻辑与从单体到集群的并发问题","slug":"Redis实战-单体架构下的一人一单功能实现","date":"2025-12-17T07:56:06.000Z","updated":"2025-12-17T08:08:45.115Z","comments":true,"path":"2025/12/17/Redis实战-单体架构下的一人一单功能实现/","permalink":"https://shaned711.github.io/2025/12/17/Redis%E5%AE%9E%E6%88%98-%E5%8D%95%E4%BD%93%E6%9E%B6%E6%9E%84%E4%B8%8B%E7%9A%84%E4%B8%80%E4%BA%BA%E4%B8%80%E5%8D%95%E5%8A%9F%E8%83%BD%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"一、 业务背景在“优惠券秒杀”场景中，为了防止用户恶意刷单、保障活动公平性，业务规则强制要求：同一个用户 ID 对同一张优惠券只能下单一次。 在低并发场景下，这是一个简单的“查询校验 -&gt; 扣减库存 -&gt; 创建订单”的串行逻辑。但在高并发场景下，如果两个线程同时进入“查询”阶段，都会判定当前用户未下单，从而同时执行后续的创建订单逻辑，导致数据库中产生同一用户的多条订单，违背了业务规则。 本文将复盘该功能在单体架构下的实现细节，以及随着架构升级为集群部署后，并发问题是如何再次出现并最终通过分布式锁解决的。 二、 单体架构下的解决方案在项目初期，服务采用单节点部署（单个 JVM）。为了解决并发安全问题，我利用 Java 原生的 synchronized 关键字实现了互斥锁。 虽然代码量不大，但为了在保证数据一致性的同时兼顾系统性能，我重点解决了以下四个问题： 1. 锁粒度的优化：从方法锁到对象锁初步方案：直接在 Service 的方法上添加 synchronized 关键字。 存在问题：这样做会将锁的范围扩大到整个方法，锁的对象是 this（当前 Service 实例）。这意味着所有用户（无论 ID 是否相同）在抢购时都需要排队，将并发操作变成了完全的串行操作，系统吞吐量极低。 优化实现：缩小锁的范围，只锁当前用户的 ID。 我将锁改为 synchronized(userId) 代码块。这样，只有 userId 相同的并发请求才会互斥排队，不同用户的请求可以并行处理，极大提升了并发性能。 2. 锁对象的唯一性：String.intern() 的应用技术难点：userId 是 Long 类型，将其转换为 String 作为锁对象时，Java 每次都会在堆内存中创建一个新的 String 对象。即便两个请求的 userId 值都是 1001，但在内存地址上它们是两个不同的对象。synchronized 判定为不同的锁，导致互斥失效。 解决方案：使用 userId.toString().intern()。 .intern() 方法会强制去 Java 的字符串常量池中查找。如果池中已存在该值的字符串，则返回池中的对象引用。这确保了只要 ID 值相同，获取到的锁对象内存地址就一定是相同的，从而保证了锁的有效性。 3. 事务与锁的边界问题（关键点）潜在 Bug：如果将 synchronized 代码块写在带有 @Transactional 注解的事务方法内部，会存在数据不一致风险。 时序分析： 线程 A 执行完业务逻辑，释放锁。 此时 Spring 的事务尚未提交（事务提交通常在方法结束后的 AOP 切面中完成），数据库中暂无数据。 就在“锁释放”与“事务提交”之间的时间差内，线程 B 获取到锁，查询数据库。 由于 A 未提交，B 查到的依然是“未购买”，B 继续下单，导致并发问题。 解决方案：扩大锁的范围，将其包裹在事务方法之外。 在调用事务方法之前先加锁，确保只有当事务完全提交之后，锁才会被释放，后续线程才能进入。 4. Spring 事务失效的修复（AOP 代理）引入问题：将锁移到事务方法外部后，变成了“普通方法调用事务方法”。由于这是在同一个类内部直接调用同类的另一个方法（this.xxx()），请求没有经过 Spring 的 AOP 代理类，被调用方法的 @Transactional 也就失效了，因为它是靠代理生效的 解决方案： 引入 AspectJ 依赖，通过 AopContext.currentProxy() 获取当前的代理对象，利用代理对象调用事务方法，确保事务切面生效。 最终代码逻辑抽象： 123456789101112131415161718// 入口方法（无事务）public void seckillVoucher(Long userId) &#123; // 锁住特定用户，使用 intern 确保锁对象唯一 synchronized(userId.toString().intern()) &#123; // 获取代理对象，防止事务失效 IVoucherOrderService proxy = (IVoucherOrderService) AopContext.currentProxy(); // 通过代理对象调用事务方法 proxy.createVoucherOrder(userId); &#125;&#125;// 事务方法@Transactionalpublic void createVoucherOrder(Long userId) &#123; // 1. 查询订单是否存在 // 2. 扣减库存 // 3. 创建订单&#125; 三、 集群架构下的失效分析随着业务量增长，我们将服务升级为集群架构（利用 Nginx 负载均衡，部署了两个节点：8081 和 8082）。 在集群模式下进行测试时，发现上述 synchronized 方案彻底失效。同一个用户依然可以在两台服务器上重复下单。 失效的根本原因：JVM 内存隔离 节点 8081：是一个独立的 Java 进程，拥有独立的堆内存空间。它的 synchronized 锁维护在自己的对象头（Object Header）和监视器（Monitor）中。 节点 8082：是另一个独立的 Java 进程，拥有另一块堆内存。 互不可见：当 Nginx 将同一个用户的两个请求分别分发到 8081 和 8082 时，两个节点都检查自己的内存，发现“没有锁”，于是同时执行业务。 结论：Java 原生的锁机制（synchronized&#x2F;Lock）只能解决单进程内的并发问题，无法解决跨进程（多节点）的并发问题。 四、 最终演进：分布式锁为了解决集群环境下的并发安全问题，我们需要将锁的控制权从 JVM 内存中移出，存储在一个所有服务节点都能访问的公共存储组件中。 本项目引入了 Redis 来实现分布式锁。 1. 核心原理利用 Redis 的 SETNX (SET if Not eXists) 命令。该命令具有原子性：只有当 Key 不存在时才能写入成功。 获取锁：所有节点在执行业务前，先尝试向 Redis 写入一个特定的 Key（如 lock:order:userId）。 写入成功（返回 1）：视为获取锁成功，执行业务。 写入失败（返回 0）：视为获取锁失败，说明其他节点正在处理该用户的请求，当前请求由于互斥被拦截。 释放锁：业务执行完毕后，删除该 Key。 2. 架构转变 Before (单体)：线程抢夺的是 JVM 堆内存 中的对象监视器。 After (集群)：线程抢夺的是 Redis 中的唯一 Key。 通过这种方式，我们实现了跨 JVM 进程的互斥控制，无论架构扩展到多少个节点，同一用户的操作都必须经过 Redis 的统一排队，解决了集群下的“一人一单”问题。 五、 总结该功能的实现有以下技术点： 并发性能优化：理解锁粒度对吞吐量的影响，避免盲目加锁。 JVM 内存机制：通过 intern() 解决了对象引用导致的锁失效问题。 Spring 源码原理：深入理解了 Spring 事务的生效边界（Transaction）与动态代理（AOP）的调用机制。 分布式架构思维：清晰认识到本地锁在集群环境下的局限性，并能够根据业务场景引入 Redis 分布式锁解决跨进程并发问题。","categories":[],"tags":[]},{"title":"Redis实战: 利用逻辑过期解决缓存击穿","slug":"Redis实战-利用逻辑过期解决缓存击穿","date":"2025-12-14T10:42:51.000Z","updated":"2025-12-14T11:01:47.625Z","comments":true,"path":"2025/12/14/Redis实战-利用逻辑过期解决缓存击穿/","permalink":"https://shaned711.github.io/2025/12/14/Redis%E5%AE%9E%E6%88%98-%E5%88%A9%E7%94%A8%E9%80%BB%E8%BE%91%E8%BF%87%E6%9C%9F%E8%A7%A3%E5%86%B3%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF/","excerpt":"","text":"一、 什么是缓存击穿？缓存击穿（Cache Breakdown） 是指一个热点 Key（比如某次秒杀活动的商品详情），在某个时间点过期了。恰好在这个时间点，有大量的并发请求访问这个 Key。这些请求发现缓存过期，瞬间全部打到数据库上，就像在防线上凿穿了一个洞，导致数据库压力激增甚至宕机。 核心特征： 高并发：访问量巨大。 热点 Key：大家都在查同一个数据。 瞬间失效：缓存 TTL 到期，数据物理消失。 二、 互斥锁&amp;逻辑过期面对缓存击穿，通常有两种解法： 1. 互斥锁（Mutex Lock） 思路：谁发现缓存过期了，谁就去抢一把锁。抢到锁的人去查数据库写缓存，其他人排队等待。 优点：数据强一致性（查到的绝对是新的）。 缺点：性能较差。所有人都得等那一个线程干完活，如果不巧那个线程挂了或慢了，后面就是灾难性的阻塞。 2. 逻辑过期（Logical Expiration） 思路：“永不过期”。不在 Redis 层面设置 TTL，而是把过期时间写在 Value 里面。发现“逻辑”过期后，先返回旧数据，然后异步开个线程去后台更新。 优点：高可用，性能极佳。用户永远不需要等待，拿了数据就走。 缺点：数据存在短暂的不一致（在重建完成前，用户看到的是旧数据）。 三、 逻辑过期的实现原理我们不使用 Redis 的 setex 来控制生死，而是引入一个包装类 RedisData，人为地记录一个 expireTime。 1. 数据结构设计我们需要一个容器来封装真实的业务数据和逻辑过期时间： 12345@Datapublic class RedisData &#123; private LocalDateTime expireTime; // 逻辑过期时间 private Object data; // 真实的业务数据（如 Shop 对象）&#125; 2. 执行流程图解 查询缓存：从 Redis 取出数据（逻辑过期前提是数据必须预热，如果 Redis 没数据，直接返回空或降级）。 判断逻辑时间： 如果 expireTime &gt; now()：数据新鲜，直接返回。 如果 expireTime &lt;&#x3D; now()：逻辑已过期。 重建缓存： 抢锁：尝试获取互斥锁。 抢锁失败：说明有人在更新了，不要等，直接返回旧数据。 抢锁成功：再次检查缓存是否已更新（Double Check）。如果没更新，则开启独立线程查库写缓存；如果已更新，直接释放锁并返回新数据。 返回数据：无论是否抢到锁，主线程都直接返回数据（旧的或新的）。 四、 代码实现 (Java)以下是基于 SpringBoot + StringRedisTemplate 的完整实现，包含了二次检查（Double Check）逻辑。 1. 缓存预热因为 Redis 里没有 TTL，数据不会自己消失。我们需要在活动开始前把数据“预热”进去。 123456789101112131415161718/** * 预热数据到 Redis * @param id 商品ID * @param expireSeconds 逻辑过期时间（秒） */public void saveShop2redis(Long id, Long expireSeconds) &#123; // 1. 查询数据库 Shop shop = getById(id); // 2. 封装成 RedisData RedisData redisData = new RedisData(); redisData.setData(shop); // 重点：设置逻辑过期时间 = 当前时间 + 指定秒数 (注意单位是 PlusSeconds) redisData.setExpireTime(LocalDateTime.now().plusSeconds(expireSeconds)); // 3. 写入 Redis (不设置 TTL) stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY + id, JSONUtil.toJsonStr(redisData));&#125; 2. 业务逻辑 (queryWithLogicalExpire)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879// 线程池：用于异步重建缓存private static final ExecutorService CACHE_REBUILD_EXECUTOR = Executors.newFixedThreadPool(10);public Shop queryWithLogicalExpire(Long id) &#123; String key = RedisConstants.CACHE_SHOP_KEY + id; // 1. 从 Redis 查询 String shopJson = stringRedisTemplate.opsForValue().get(key); // 2. 如果未命中（未预热），直接返回 null if (StrUtil.isBlank(shopJson)) &#123; return null; &#125; // 3. 反序列化 RedisData redisData = JSONUtil.toBean(shopJson, RedisData.class); JSONObject data = (JSONObject) redisData.getData(); Shop shop = JSONUtil.toBean(data, Shop.class); LocalDateTime expireTime = redisData.getExpireTime(); // 4. 判断是否过期 if (expireTime.isAfter(LocalDateTime.now())) &#123; // 未过期，直接返回 return shop; &#125; // ========================================================== // 5. 已过期，需要缓存重建 // ========================================================== String lockKey = RedisConstants.LOCK_SHOP_KEY + id; // 6. 尝试获取互斥锁 boolean isLock = tryLock(lockKey); if (isLock) &#123; // 6.1 获取锁成功 // 【二次检查 (Double Check)】 // 再次查询 Redis，防止在上一个线程释放锁的瞬间，缓存已经被更新了 shopJson = stringRedisTemplate.opsForValue().get(key); if (StrUtil.isNotBlank(shopJson)) &#123; RedisData newRedisData = JSONUtil.toBean(shopJson, RedisData.class); LocalDateTime newExpireTime = newRedisData.getExpireTime(); // 如果发现已经被更新（不过期了） if (newExpireTime.isAfter(LocalDateTime.now())) &#123; // 释放锁，直接返回新数据，不再开启线程重建 unlock(lockKey); return JSONUtil.toBean((JSONObject) newRedisData.getData(), Shop.class); &#125; &#125; // 6.2 确认依然过期，开启独立线程重建 CACHE_REBUILD_EXECUTOR.submit(() -&gt; &#123; try &#123; // 重建缓存（假设逻辑过期时间 20秒） this.saveShop2redis(id, 20L); &#125; catch (Exception e) &#123; e.printStackTrace(); // 建议使用 log.error &#125; finally &#123; // 释放锁 unlock(lockKey); &#125; &#125;); &#125; // 7. 【核心】无论是否抢到锁，都直接返回旧数据，绝不等待！ return shop;&#125;// 辅助方法：获取锁private boolean tryLock(String key) &#123; Boolean flag = stringRedisTemplate.opsForValue().setIfAbsent(key, &quot;1&quot;, 10, TimeUnit.SECONDS); return BooleanUtil.isTrue(flag);&#125;// 辅助方法：释放锁private void unlock(String key) &#123; stringRedisTemplate.delete(key);&#125; 五、 总结1. 为什么选择逻辑过期？逻辑过期本质上是一种**“妥协的艺术”**。它牺牲了短暂的数据一致性（用户可能在几百毫秒内看到旧数据），换取了系统在极高并发下的稳定性（Redis 永不阻塞，数据库压力极小）。 2. 为什么要做二次检查 (Double Check)？如果不加二次检查，在高并发下，线程 B 可能会在线程 A 重建完刚刚释放锁的时候抢到锁。此时线程 B 以为数据还过期，会再次开启线程去查库。虽然不影响正确性，但浪费了性能。加上二次检查可以避免不必要的重建。","categories":[],"tags":[]},{"title":"Spring Boot 实战：基于 Redis + Token 实现分布式登录系统","slug":"Spring-Boot-实战：基于-Redis-Token-实现分布式登录系统","date":"2025-12-10T08:32:46.000Z","updated":"2025-12-10T08:49:26.155Z","comments":true,"path":"2025/12/10/Spring-Boot-实战：基于-Redis-Token-实现分布式登录系统/","permalink":"https://shaned711.github.io/2025/12/10/Spring-Boot-%E5%AE%9E%E6%88%98%EF%BC%9A%E5%9F%BA%E4%BA%8E-Redis-Token-%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E7%99%BB%E5%BD%95%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"1. 设计思路在分布式系统或前后端分离的架构中，我们需要一种无状态的登录方案。核心设计思路如下： 凭证机制：使用 Token（随机字符串）作为用户身份的唯一标识，替代传统的 Cookie。 数据存储：将用户的登录状态（Token 与用户信息的映射）存储在 Redis 中，利用其高性能和自动过期机制。 状态管理： Redis：作为服务端共享的“会话存储中心”。 ThreadLocal：作为单次请求内的“上下文容器”，方便 Controller 和 Service 层获取用户信息。 请求拦截：采用 双拦截器模式，分离“Token 刷新”与“登录鉴权”的职责。 2. 代码实现2.1 步骤一：发送短信验证码验证码需要有短期的有效期（如 2 分钟），适合使用 Redis 的 String 结构存储。 Key: login:code:{手机号} Value: 验证码数字 123456789101112131415161718@Overridepublic Result sendCode(String phone) &#123; // 1. 校验手机号格式 if (RegexUtils.isPhoneInvalid(phone)) &#123; return Result.fail(&quot;手机号格式错误&quot;); &#125; // 2. 生成 6 位随机验证码 String code = RandomUtil.randomNumbers(6); // 3. 保存验证码到 Redis // 设置 2 分钟过期 stringRedisTemplate.opsForValue().set(RedisConstants.LOGIN_CODE_KEY + phone, code, 2, TimeUnit.MINUTES); // 4. 模拟发送短信（实际项目中调用短信服务商 API） log.debug(&quot;发送验证码成功，验证码：&#123;&#125;&quot;, code); return Result.ok();&#125; 2.2 步骤二：登录并生成 Token登录成功后，我们需要生成 Token，并将用户对象存储为 Redis 的 Hash 结构。Hash 结构适合存储对象，且内存占用更优。 Key: login:token:{随机Token} Value: User 对象的字段映射 (Hash) 123456789101112131415161718192021222324252627282930313233343536373839@Overridepublic Result login(LoginFormDTO loginForm) &#123; String phone = loginForm.getPhone(); // 1. 从 Redis 获取验证码并校验 String cacheCode = stringRedisTemplate.opsForValue().get(RedisConstants.LOGIN_CODE_KEY + phone); String code = loginForm.getCode(); if (cacheCode == null || !cacheCode.equals(code)) &#123; return Result.fail(&quot;验证码错误&quot;); &#125; // 2. 根据手机号查询用户（若不存在则注册，代码略） User user = query().eq(&quot;phone&quot;, phone).one(); if (user == null) &#123; user = createUserWithPhone(phone); &#125; // 3. 生成随机 Token (作为登录令牌) String token = UUID.randomUUID().toString(true); // 4. 将 User 对象转为 HashMap 存储 // 核心细节：StringRedisTemplate 要求 Value 必须是 String， // 所以必须将 Long 类型的 ID 强转为 String，否则会报 ClassCastException UserDTO userDTO = BeanUtil.copyProperties(user, UserDTO.class); Map&lt;String, Object&gt; userMap = BeanUtil.beanToMap(userDTO, new HashMap&lt;&gt;(), CopyOptions.create() .setIgnoreNullValue(true) .setFieldValueEditor((fieldName, fieldValue) -&gt; fieldValue.toString())); // 5. 存储到 Redis String tokenKey = RedisConstants.LOGIN_USER_KEY + token; stringRedisTemplate.opsForHash().putAll(tokenKey, userMap); // 6. 设置有效期（例如 30 分钟） stringRedisTemplate.expire(tokenKey, RedisConstants.LOGIN_USER_TTL, TimeUnit.MINUTES); // 7. 返回 Token 给前端 return Result.ok(token);&#125; 12345678Redis 数据库│├── Key: &quot;login:token:xyz-123&quot; &lt;-- 这是你设置的 Redis Key (Token)│ ││ └── Value (Hash结构) &lt;-- 这是一个大容器│ ├── Field: &quot;id&quot; --&gt; Value: &quot;101&quot; (必须是 String)│ ├── Field: &quot;nickName&quot; --&gt; Value: &quot;小明&quot; (必须是 String)│ └── Field: &quot;icon&quot; --&gt; Value: &quot;/a.jpg&quot; (必须是 String) 2.3 步骤三：构建“双拦截器”防御体系为了实现 “用户只要在使用 App，登录状态就一直有效” 的无感刷新体验，我们将拦截器拆分为两层。 第一层：Token 刷新拦截器 (RefreshTokenInterceptor) 拦截路径：所有路径 (/**) 职责：只要携带了 Token，就刷新 Redis 有效期，并保存用户信息到 ThreadLocal。不负责拦截请求。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class RefreshTokenInterceptor implements HandlerInterceptor &#123; private StringRedisTemplate stringRedisTemplate; // 构造函数注入 StringRedisTemplate public RefreshTokenInterceptor(StringRedisTemplate stringRedisTemplate) &#123; this.stringRedisTemplate = stringRedisTemplate; &#125; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; // 1. 获取请求头中的 token String token = request.getHeader(&quot;authorization&quot;); if (StrUtil.isBlank(token)) &#123; return true; // 没 Token 也放行，交给下一道拦截器 &#125; // 2. 基于 token 获取 Redis 中的用户 String key = RedisConstants.LOGIN_USER_KEY + token; Map&lt;Object, Object&gt; userMap = stringRedisTemplate.opsForHash().entries(key); // 3. 判断用户是否存在 if (userMap.isEmpty()) &#123; return true; // Token 无效或过期，也放行 &#125; // 4. 将查询到的 Map 转为 UserDTO 对象 UserDTO userDTO = BeanUtil.fillBeanWithMap(userMap, new UserDTO(), false); // 5. 保存到 ThreadLocal (供后续业务使用) UserHolder.saveUser(userDTO); // 6. 【核心动作】刷新 Token 有效期 stringRedisTemplate.expire(key, RedisConstants.LOGIN_USER_TTL, TimeUnit.MINUTES); // 7. 放行 return true; &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; // 请求结束，清理 ThreadLocal，防止内存泄漏 UserHolder.removeUser(); &#125;&#125; 第二层：登录拦截器 (LoginInterceptor) 拦截路径：敏感业务路径 (排除首页、登录接口等) 职责：只检查 ThreadLocal 是否有用户。如果没有，则拦截并返回 401。 12345678910111213public class LoginInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; // 1. 判断 ThreadLocal 中是否有用户 if (UserHolder.getUser() == null) &#123; // 2. 没有用户，拦截并返回 401 (未授权) response.setStatus(401); return false; &#125; // 3. 有用户，放行 return true; &#125;&#125; 2.4 步骤四：配置拦截器 (MvcConfig)在配置类中注册这两个拦截器，并通过 order 控制执行顺序：先刷新，后拦截。 12345678910111213141516171819202122232425262728@Configurationpublic class MvcConfig implements WebMvcConfigurer &#123; @Resource private StringRedisTemplate stringRedisTemplate; @Override public void addInterceptors(InterceptorRegistry registry) &#123; // 1. 注册刷新拦截器 (Order = 0, 最先执行) // 拦截所有请求，确保用户访问任何页面都能刷新 Token registry.addInterceptor(new RefreshTokenInterceptor(stringRedisTemplate)) .addPathPatterns(&quot;/**&quot;) .order(0); // 2. 注册登录拦截器 (Order = 1, 后执行) // 只拦截需要保护的接口 registry.addInterceptor(new LoginInterceptor()) .excludePathPatterns( &quot;/user/login&quot;, &quot;/user/code&quot;, &quot;/blog/hot&quot;, &quot;/shop/**&quot;, &quot;/shop-type/**&quot;, &quot;/upload/**&quot;, &quot;/voucher/**&quot; ).order(1); &#125;&#125; 3. 业务层使用在 Controller 或 Service 层，无需再操作 Request 或 Redis，直接从 ThreadLocal 获取当前登录用户即可。 123456@GetMapping(&quot;/me&quot;)public Result me()&#123; // 直接获取当前用户 UserDTO user = UserHolder.getUser(); return Result.ok(user);&#125; 4. 总结这套 Redis + Token + 双拦截器 的方案具有以下优势： 高性能：Redis 的读写速度极快，不会拖慢请求响应。 无感刷新：通过 RefreshTokenInterceptor，解决了用户在使用过程4中 Token 突然过期的问题。 职责单一：登录逻辑只负责生成 Token，拦截器只负责鉴权，业务层只负责业务，代码结构清晰，耦合度低。","categories":[],"tags":[]},{"title":"Spring Boot 实战：基于拦截器与 ThreadLocal 的用户登录校验","slug":"Spring-Boot-实战：基于拦截器与-ThreadLocal-的用户登录校验","date":"2025-12-09T08:56:52.000Z","updated":"2025-12-09T09:08:25.340Z","comments":true,"path":"2025/12/09/Spring-Boot-实战：基于拦截器与-ThreadLocal-的用户登录校验/","permalink":"https://shaned711.github.io/2025/12/09/Spring-Boot-%E5%AE%9E%E6%88%98%EF%BC%9A%E5%9F%BA%E4%BA%8E%E6%8B%A6%E6%88%AA%E5%99%A8%E4%B8%8E-ThreadLocal-%E7%9A%84%E7%94%A8%E6%88%B7%E7%99%BB%E5%BD%95%E6%A0%A1%E9%AA%8C/","excerpt":"","text":"1. 背景与问题在无状态的 HTTP 协议下，Web 应用通常使用 Session 或 Token 机制来维持用户的登录状态。在 Spring Boot 后端开发中，面临两个核心问题： 统一校验：如何在请求到达业务逻辑之前，统一拦截未登录请求，避免在每个 Controller 方法中重复编写校验代码？ 上下文共享：在 Controller、Service 甚至 Dao 层中，如何优雅地获取当前登录用户的信息，而不需要层层传递 User 对象参数？ 这里介绍登录 + 拦截器 (Interceptor) + 线程本地变量 (ThreadLocal)” 2. 架构设计该方案的流程如下： 登录接口：负责认证身份，并将用户信息存入 HttpSession。 拦截器 (preHandle)：在请求进入 Controller 之前拦截。校验 Session 中是否存在用户信息。 若存在：将用户信息读取并存入当前线程的 ThreadLocal 中，放行。 若不存在：拦截请求，返回 401 状态码。 业务层 (Controller&#x2F;Service)：需要用户信息时，直接从 ThreadLocal 中获取，无需依赖 Session API。 拦截器 (afterCompletion)：请求结束，响应返回前，移除 ThreadLocal 中的用户信息，防止内存泄漏。 3. 代码实现步骤3.1 封装 ThreadLocal 工具类 (UserHolder)为了在同一线程内共享数据，我们需要封装一个基于 ThreadLocal 的工具类。它充当了线程内全局容器的角色。 12345678910111213141516171819public class UserHolder &#123; // 使用 ThreadLocal 保存用户信息，UserDTO 为脱敏后的用户对象 private static final ThreadLocal&lt;UserDTO&gt; tl = new ThreadLocal&lt;&gt;(); // 保存用户 public static void saveUser(UserDTO user)&#123; tl.set(user); &#125; // 获取用户 public static UserDTO getUser()&#123; return tl.get(); &#125; // 移除用户（防止内存泄漏的关键） public static void removeUser()&#123; tl.remove(); &#125;&#125; 3.2 自定义登录拦截器 (LoginInterceptor)拦截器实现 HandlerInterceptor 接口，负责“校验”和“上下文传递”。 12345678910111213141516171819202122232425262728293031public class LoginInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; // 1. 获取 Session HttpSession session = request.getSession(); // 2. 获取 Session 中的用户 Object user = session.getAttribute(&quot;user&quot;); // 3. 校验用户是否存在 if (user == null) &#123; // 4. 不存在，拦截，设置状态码 401 (未授权) response.setStatus(401); return false; &#125; // 5. 存在，将用户信息保存到 ThreadLocal // 这一步实现了从 Web 层 (Session) 到 业务层 (ThreadLocal) 的状态转移 UserHolder.saveUser((UserDTO) user); // 6. 放行 return true; &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; // 7. 必须移除用户，避免线程池复用导致的“数据串号”和内存泄漏 UserHolder.removeUser(); &#125;&#125; 3.3 注册拦截器 (MvcConfig)通过实现 WebMvcConfigurer 接口，将自定义拦截器注册到 Spring MVC 的拦截链中，并配置拦截路径。 123456789101112131415@Configurationpublic class MvcConfig implements WebMvcConfigurer &#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new LoginInterceptor()) .excludePathPatterns( &quot;/user/code&quot;, // 发送验证码 &quot;/user/login&quot;, // 登录接口 &quot;/blog/hot&quot;, // 热门博客 &quot;/shop/**&quot;, // 店铺详情 &quot;/shop-type/**&quot; // 店铺类型 ).order(1); &#125;&#125; 3.4 业务层获取用户信息 (/user/me)在 Controller 中，我们不再需要操作 HttpSession 或 HttpServletRequest，直接调用 UserHolder 即可。 123456@GetMapping(&quot;/me&quot;)public Result me()&#123; // 直接从 ThreadLocal 获取当前请求关联的用户信息 UserDTO user = UserHolder.getUser(); return Result.ok(user);&#125; 4. 组件关系这套机制中，各组件的职责与关系如下： 4.1 拦截器 (Interceptor) 与 Session 的关系 关系：读取者与存储者。 解析：Session 是由 Tomcat 容器管理的服务器内存存储。拦截器作为请求处理的第一道关卡，负责从 Session 中读取状态。拦截器并不产生用户数据，它只是校验 Session 中是否已由登录接口写入了数据。 4.2 拦截器 (Interceptor) 与 ThreadLocal 的关系 关系：生产者与容器。 解析：这是本架构最精妙的地方。拦截器在 preHandle 阶段充当“搬运工”，将 Session 中的数据（Web 作用域）复制到 ThreadLocal（线程作用域）。这使得后续的 Service 层代码可以完全脱离 javax.servlet API，实现了业务逻辑与 Web 容器的解耦。 4.3 Controller&#x2F;Service 与 ThreadLocal 的关系 关系：消费者与容器。 解析：Controller 或 Service 层完全不需要知道拦截器的存在，也不需要知道数据是从 Session 来的还是 Token 来的。它们只需要信任 UserHolder，认为“只要代码执行到这里，UserHolder 里一定有当前用户”，从而简化了代码逻辑。 5. 总结实现这套登录校验拦截机制，本质上是为了解决两个工程化问题： 安全性（Secur11ity）：通过拦截器实现统一的权限控制，防止未登录用户访问12受保护资源。 代码解耦（Decoupling）：利用 ThreadLocal 替代参数传递，使得用户信息可以在同一请求线程的任意位置被访问，极大地提高了代码的可维护性。 在后续的分布式演进中（如引入 Redis），我们只需要修改 登录接口（存 Redis） 和 拦截器（查 Redis） 的逻辑，而业务层获取用户信息的代码（UserHolder.getUser()）完全不需要改动，这体现了良好的架构扩展性。","categories":[],"tags":[]},{"title":"解决Rocky Linux 9无法使用Root用户SSH远程连接的问题","slug":"解决Rocky-Linux-9无法使用Root用户SSH远程连接的问题","date":"2025-12-03T08:48:28.000Z","updated":"2025-12-03T08:55:35.331Z","comments":true,"path":"2025/12/03/解决Rocky-Linux-9无法使用Root用户SSH远程连接的问题/","permalink":"https://shaned711.github.io/2025/12/03/%E8%A7%A3%E5%86%B3Rocky-Linux-9%E6%97%A0%E6%B3%95%E4%BD%BF%E7%94%A8Root%E7%94%A8%E6%88%B7SSH%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"我在 VMware 虚拟机中安装了最新的 Rocky Linux 9。 遇到了一个非常奇怪的问题：在虚拟机的黑窗口（控制台）中，使用 root 账号和密码可以正常登录。但是当使用 FinalShell 或 Xshell 等 SSH 工具进行远程连接时，输入了正确的密码，却一直提示“认证失败”或无限循环要求输入密码。 经过排查，发现这是 Rocky Linux 9（以及较新的 Linux 发行版）默认的安全策略导致的。这里记录一下解决方案。 进入配置文件 在虚拟机的终端中，输入以下命令编辑 sshd_config 文件： 1vi /etc/ssh/sshd_config 修改配置项进入编辑器后（如果是 vi&#x2F;vim）： 按 / 键进入搜索模式，输入 PermitRootLogin 并回车，找到对应的行。 按 i 键进入编辑模式。 找到 PermitRootLogin 这一项。它被设置成了 prohibit-password。 将其修改为： 1PermitRootLogin yes 保存并退出按 Esc 键退出编辑模式，输入 :wq 保存并退出。 验证回到 FinalShell，再次尝试使用 root 用户连接，就能秒连成功了 在生产环境（公司服务器）中，为了安全起见，通常不建议开启 root 远程登录，最好创建一个普通用户并配置 sudo 权限。但在本地虚拟机学习 Redis 或 Java 开发时，开启 root 权限能省去很多麻烦。","categories":[],"tags":[]},{"title":"Nginx 前后端分离架构配置：静态托管、API 反向代理与 WebSocket集成","slug":"Nginx-前后端分离架构配置详解：静态托管、API-反向代理与-WebSocket集成","date":"2025-12-01T07:06:12.000Z","updated":"2025-12-01T07:36:59.271Z","comments":true,"path":"2025/12/01/Nginx-前后端分离架构配置详解：静态托管、API-反向代理与-WebSocket集成/","permalink":"https://shaned711.github.io/2025/12/01/Nginx-%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E6%9E%B6%E6%9E%84%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3%EF%BC%9A%E9%9D%99%E6%80%81%E6%89%98%E7%AE%A1%E3%80%81API-%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E4%B8%8E-WebSocket%E9%9B%86%E6%88%90/","excerpt":"","text":"本次部署采用经典的 反向代理（Reverse Proxy） 模式。 流量入口：Nginx 监听宿主机的 80 端口。 前端应用：Vue 构建后的静态资源（HTML&#x2F;CSS&#x2F;JS），托管于 Nginx 本地。 后端服务：Spring Boot 应用运行于 8081 端口，不再直接对外暴露。 通信链路： HTTP 请求：由 Nginx 进行路径重写后转发。 WebSocket 连接：由 Nginx 处理握手并建立全双工 TCP 隧道。 1. Nginx 完整配置代码这是我目前正在使用的配置。Nginx 监听 80 端口，后端 Tomcat 运行在 8081 端口。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; map $http_upgrade $connection_upgrade&#123; default upgrade; &#x27;&#x27; close; &#125; upstream webservers&#123; server 127.0.0.1:8081 weight=90 ; #server 127.0.0.1:8088 weight=10 ; &#125; # 主服务器配置 server &#123; listen 80; server_name localhost; location / &#123; root html/sky; index index.html index.htm; &#125; # 错误页面 error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root /opt/homebrew/var/www; &#125; location /api/ &#123; proxy_pass http://webservers/admin/; &#125; location /user/ &#123; proxy_pass http://webservers/user/; &#125; # WebSocket location /ws/ &#123; proxy_pass http://webservers/ws/; proxy_http_version 1.1; proxy_read_timeout 3600s; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;$connection_upgrade&quot;; &#125; &#125;&#125; 2. 配置详解：各部分的作用第一部分：Server 核心路由块123456server &#123; listen 80; server_name localhost; # ... locations ...&#125; Nginx 监听 80 端口，拦截所有发往 localhost 的请求，并根据 URI 前缀 进行路由分发。 第二部分：静态资源托管 加载前端页面 (Location &#x2F;)1234location / &#123; root html/sky; index index.html index.htm;&#125; 触发条件：当你在浏览器输入 http://localhost 时 处理逻辑：Nginx 不会去问后端，而是直接去电脑硬盘的 html/sky 目录下，找到 index.html 文件发送给浏览器，然后浏览器显示出网页界面。 第三部分：定义后端地址 (Upstream)123upstream webservers&#123; server 127.0.0.1:8081 weight=90 ;&#125; 作用：给运行在 8081 端口的 Java 后端起个名字叫 webservers。 好处：以后如果后端换了端口或增加了服务器，只需要改这里，下面的配置不用动。 第四部分：API 反向代理 转发业务接口 (Location &#x2F;api&#x2F;)123location /api/ &#123; proxy_pass http://webservers/admin/; &#125; 触发条件：当前端代码发起登录或查询等请求时（如 http://localhost/api/employee/login）。 处理逻辑： Nginx 拦截到路径里包含 /api/。 proxy_pass 将请求转发给 webservers 组（即 8081 端口）。 注意路径替换：Nginx 会把 URL 中的 /api/ 替换为 /admin/，因为后端接口定义的路径是 /admin/... 示例： 客户端请求：http://localhost/api/employee/login Nginx 转发：http://127.0.0.1:8081/admin/employee/login 结果：Java 后端收到请求，处理业务，返回数据。 第五部分：用户端接口转发123location /user/ &#123; proxy_pass http://webservers/user/;&#125; 逻辑：同上，将 /user/ 开头的请求转发到后端的 /user/ 模块，实现了管理端与用户端流量的物理隔离与逻辑统一。 第六部分：转发 WebSocket (Location &#x2F;ws&#x2F;)123456location /ws/ &#123; proxy_pass http://webservers/ws/; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;$connection_upgrade&quot;;&#125; 触发条件：前端发起 ws://localhost/ws/xxx 连接请求时。 处理逻辑： proxy_pass：将请求转发给后端的 WebSocket 地址。 proxy_set_header：这是最关键的。它会在请求头里加上 Upgrade: websocket。如果不加这两行，后端会以为这只是普通的 HTTP 请求从而拒绝建立长连接。 结果：浏览器与后端建立了一条全双工的通信通道，用于实时消息推送。 3. 完整交互流程总结在这个架构下，前端、Nginx、后端是这样配合的： 用户访问网页： 浏览器 -&gt; Nginx (80端口) -&gt; 读取硬盘文件 -&gt; 返回 HTML 页面。 (此时后端不参与) 用户点击操作（如登录）： 浏览器 -&gt; 发送 /api/ 请求 -&gt; Nginx (80端口) -&gt; 修改路径为 /admin/ -&gt; 转发给后端 (8081端口) -&gt; 返回结果。 来单提醒（WebSocket）： 浏览器 -&gt; 发送 /ws/ 连接 -&gt; Nginx (80端口) -&gt; 添加协议升级头 -&gt; 转发给后端 (8081端口) -&gt; 建立长连接。 之后后端有新消息，直接通过这个连接推送到浏览器。 通过这套配置，成功实现了前后端分离的部署，并且对外只暴露一个 80 端口，既规范又安全。","categories":[],"tags":[]},{"title":"BaseContext：如何在Service层“隔空取物”获取当前登录用户ID？","slug":"BaseContext：如何在-Service-层“隔空取物”获取当前登录用户-ID？","date":"2025-11-28T06:37:54.000Z","updated":"2025-11-28T06:59:43.034Z","comments":true,"path":"2025/11/28/BaseContext：如何在-Service-层“隔空取物”获取当前登录用户-ID？/","permalink":"https://shaned711.github.io/2025/11/28/BaseContext%EF%BC%9A%E5%A6%82%E4%BD%95%E5%9C%A8-Service-%E5%B1%82%E2%80%9C%E9%9A%94%E7%A9%BA%E5%8F%96%E7%89%A9%E2%80%9D%E8%8E%B7%E5%8F%96%E5%BD%93%E5%89%8D%E7%99%BB%E5%BD%95%E7%94%A8%E6%88%B7-ID%EF%BC%9F/","excerpt":"","text":"在做Spring Boot 的 Web 项目时，在 Controller 或 Service 层经常会看到这样一行代码： 12// 在 Service 层直接获取当前登录用户的ID Long userId = BaseContext.getCurrentId(); 这就很神奇了： 没有传参：Controller 调用 Service 时，并没有把 userId 作为参数传进来 没有查库：这一行代码也没有去查询数据库 数据准确：它总是能精准地拿到当前发送请求的那个用户的 ID，张三发请求拿到张三，李四发请求拿到李四，互不干扰 它是怎么做到的？ 有两个核心概念：ThreadLocal 和 Tomcat 的“一请求一线程”模型。 1.容器：ThreadLocal (线程局部变量)BaseContext 只是一个包装类，它内部的核心是 JDK 提供的 ThreadLocal。 12345678910111213141516public class BaseContext &#123; // 核心：ThreadLocal 对象 public static ThreadLocal&lt;Long&gt; threadLocal = new ThreadLocal&lt;&gt;(); public static void setCurrentId(Long id) &#123; threadLocal.set(id); // 存入 &#125; public static Long getCurrentId() &#123; return threadLocal.get(); // 取出 &#125; public static void removeCurrentId() &#123; threadLocal.remove(); // 清除 &#125;&#125; ThreadLocal 的作用： 当我们在 线程 A 中往 ThreadLocal 存入数据时，只有 线程 A 能取出来 线程 B 即使访问同一个变量，也完全摸不到 线程 A 的数据 这就是线程隔离（Thread Safety） 2.环境：Tomcat 的“一请求一线程”模型Spring Boot 内置的 Web 服务器通常是 Tomcat。Tomcat 处理请求的机制是：One Request, One Thread （一个 HTTP 请求，由一个独立的线程全程负责） 当一个用户发起请求（比如“添加购物车”）时： Tomcat 分配 线程 X 来处理这个请求 拦截器 (Interceptor) 是 线程 X 执行的 Controller 是 线程 X 执行的 Service 还是 线程 X 执行的 Mapper 依然是 线程 X 执行的 结论： 只要我们没有手动开启新线程（new Thread），整个后端业务流程就像一场接力赛，但是是同一个运动员（线程 X） 从头跑到尾 流程基于以上两个原理，我们可以还原 userId 是如何从请求头一步步流转到 Service 层的： 第一步：拦截器 (存入) 请求刚到达后端，拦截器（JwtTokenUserInterceptor）最先拦截 第二步：Controller 拦截器放行后，代码进入 Controller 第三步：Service (取出) 代码进入 Service 层 为什么要这么设计？使用 ThreadLocal (BaseContext) 的方案，实现了数据在同一线程内的“隐式传递”，让代码极其简洁优雅。 总结 BaseContext 利用 ThreadLocal 实现了线程内部的数据隔离存储。 Tomcat 保证了从拦截器到 Service 处于 同一个线程 中。 二者结合，让我们可以在 Service 层“隔空”获取 Controller 层（拦截器）解析的数据，极大简化了代码结构。","categories":[],"tags":[]},{"title":"解决idea错误提示:无法解析'表名'","slug":"解决idea错误提示-无法解析-表名","date":"2025-11-24T05:56:47.000Z","updated":"2025-11-24T06:28:43.493Z","comments":true,"path":"2025/11/24/解决idea错误提示-无法解析-表名/","permalink":"https://shaned711.github.io/2025/11/24/%E8%A7%A3%E5%86%B3idea%E9%94%99%E8%AF%AF%E6%8F%90%E7%A4%BA-%E6%97%A0%E6%B3%95%E8%A7%A3%E6%9E%90-%E8%A1%A8%E5%90%8D/","excerpt":"","text":"1. 问题现象Database 面板里已经成功连接了数据库，表都能看得到。 SQL 代码（MyBatis XML 或 @Select 注解）本身没有语法错误，在数据库里执行也能跑通。 但是IDEA 编辑器里，提示 Unable to resolve table &#39;xxx&#39;。 2. 快速解决方案这个问题的根源在于 IDEA 不知道当前的代码文件应该对应哪个数据库连接。我们需要手动设置 SQL Resolution Scope（SQL 解析作用域）。 3. 为什么会有这个问题？我明明设置了 SQL Dialect（方言），也连接了数据库，而且我只有一个数据库，IDEA 为什么不能自己匹配呢？ 3.1 三大概念的区别 SQL Dialect (方言)：相当于“语法书”。它告诉 IDEA 这段代码是 MySQL 语法还是 Oracle 语法，负责检查语法结构（如 SELECT 拼写对不对）。 Data Source (数据源)：相当于“字典”。这是真实的数据库连接，包含所有的表结构元数据。 Resolution Scope (作用域)：相当于“指针&#x2F;上下文”。它的作用是把“代码”和“字典”连起来。 飘红的原因就是： 你有了语法书，也有了字典，但 IDEA 不知道这段代码该查哪本字典。 3.2 为什么不能选 “All Data Sources”？即使只有一个数据库，选“所有数据源”依然会报错。 本质原因：缺失“默认上下文” (Default Context)。 我们在写 SQL 时通常只写短表名（如 SELECT * FROM user），而不是全限定名（如 SELECT * FROM my_db.public.user）。 当你选“具体数据库”时： 相当于进入了该数据库的 Session，拥有了默认的 Schema。IDEA 遇到 user 表，会自动去默认 Schema 下查找。(相当于相对路径：./user) 当你选“所有数据源”时： 相当于站在了服务器的“大厅”里。虽然只有一个库，但因为没有执行 USE database 这种切换上下文的操作，IDEA 面对 user 这个短名，不敢擅自猜测它是属于哪个库的。为了严谨和防止歧义，它选择报错。(相当于绝对路径缺失)","categories":[],"tags":[]},{"title":"Hexo+Typora+PicGo搭建博客配置记录","slug":"Typora-PicGo-自动上传-Hexo-静态博客配置记录","date":"2025-11-21T12:31:38.000Z","updated":"2025-11-21T13:33:11.458Z","comments":true,"path":"2025/11/21/Typora-PicGo-自动上传-Hexo-静态博客配置记录/","permalink":"https://shaned711.github.io/2025/11/21/Typora-PicGo-%E8%87%AA%E5%8A%A8%E4%B8%8A%E4%BC%A0-Hexo-%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE%E8%AE%B0%E5%BD%95/","excerpt":"","text":"Mac电脑配置一套写博客的环境,流程: 1.搭建 Hexo 博客 2.配置 PicGo + Typora 实现自动化写作 准备工作：在做任何安装之前，先解决 Git 和终端的网络问题 开启 Clash，查看端口是7897 打开终端 (Terminal)，依次执行以下命令： 123456789# 1. 让 Git 强制走代理 (解决连不上 GitHub)git config --global http.proxy http://127.0.0.1:7897git config --global https.proxy http://127.0.0.1:7897# 2. 让 Git 使用 HTTP/1.1 (解决 HTTP2 framing layer 报错)git config --global http.version HTTP/1.1# 3. 让 curl 也走 HTTP/1.1 (解决 Homebrew 下载报错)echo &quot;--http1.1&quot; &gt;&gt; ~/.curlrc 基础环境安装 (Node.js &amp; Git)123456789# 1. 给当前终端挂上全局代理 (加速下载)export https_proxy=http://127.0.0.1:7897 http_proxy=http://127.0.0.1:7897 all_proxy=http://127.0.0.1:7897# 2. 强制跳过更新，直接安装 Node.jsHOMEBREW_NO_AUTO_UPDATE=1 brew install node# 3. 验证安装node -vnpm -v 搭建 Hexo 博客主体把博客放在 ~/Documents/my-blog 12345678910111213# 1. 安装 Hexo 命令行工具npm install -g hexo-cli# 2. 初始化博客目录cd ~/Documentshexo init my-blog# 3. 进入目录并安装依赖cd my-blognpm install# 4. 安装 Git 推送插件npm install hexo-deployer-git --save 连接 GitHub 仓库在 GitHub 新建仓库 A： 仓库名：用户名.github.io (例如 ShaneD711.github.io) 权限：Public 修改 Hexo 配置： 用 IDEA 打开 my-blog 目录。 打开 _config.yml，拉到最底部，修改 deploy 部分： 1234deploy: type: git repo: https://github.com/你的用户名/你的用户名.github.io.git branch: main 回到终端，执行 1hexo cl &amp;&amp; hexo g &amp;&amp; hexo d 成功后，访问 https://你的用户名.github.io 能看到网页 配置 PicGo 图床准备 GitHub 图片仓库 在 GitHub 新建仓库 B： 仓库名：blog-imgs 权限：Public 勾选 “Add a README file”。 获取 Token： GitHub -&gt; Settings -&gt; Developer settings -&gt; Personal access tokens (classic)。 Generate new token -&gt; 勾选 repo -&gt; 生成并复制 Token。 安装 PicGo 并修复损坏提示 安装： 1brew install --cask picgo 修复“应用已损坏” ： 1sudo xattr -rd com.apple.quarantine /Applications/PicGo.app Typora 接入 打开 Typora -&gt; 设置 -&gt; 图像。 插入图片时：选择“上传图片”。 上传服务：选择 PicGo.app。 点击 “验证图片上传选项” 看到绿色的 Successfully 即可 标准日常写作流程新建： 12cd ~/Documents/my-bloghexo new &quot;文章标题&quot; 写作： 用 Typora 打开 source/_posts/文章标题.md。 截图 -&gt; 粘贴 (自动上传) -&gt; 写字 -&gt; 保存。 预览 ： 1hexo server 发布： 1hexo cl &amp;&amp; hexo g &amp;&amp; hexo d","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2025-11-21T09:39:02.256Z","updated":"2025-11-21T09:39:02.256Z","comments":true,"path":"2025/11/21/hello-world/","permalink":"https://shaned711.github.io/2025/11/21/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[],"tags":[]}